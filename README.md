# ClasificaciÃ³n BÃ¡sica de Calidad del Vino

## ğŸ“‹ DescripciÃ³n del Proyecto
Este proyecto tiene como objetivo **clasificar la calidad del vino** utilizando diferentes tÃ©cnicas de clasificaciÃ³n supervisada. Los datos provienen de caracterÃ­sticas fÃ­sico-quÃ­micas de vinos tintos y blancos, y la calidad se ha dividido en **buena** y **mala** a partir de un umbral predefinido.

El cÃ³digo se encuentra implementado en un **notebook de Jupyter**, utilizando librerÃ­as comunes en **Python** como `scikit-learn`, `pandas`, y `matplotlib`.

---

## âš™ï¸ TÃ©cnicas Implementadas

### **1. Preprocesamiento de Datos**
- Carga y exploraciÃ³n del dataset.
- ClasificaciÃ³n binaria de la variable objetivo:
  - **1**: Buena calidad (â‰¥ 6 en la columna `quality`).
  - **0**: Mala calidad.
- Escalado de caracterÃ­sticas numÃ©ricas mediante **StandardScaler**.

### **2. Modelos Utilizados**
Se implementaron los siguientes modelos de clasificaciÃ³n:
- **RegresiÃ³n LogÃ­stica**.
- **K-Nearest Neighbors (KNN)**.
- **Random Forest Classifier** (Optimizado con GridSearchCV).

### **3. EvaluaciÃ³n de Modelos**
Las mÃ©tricas utilizadas para evaluar los modelos incluyen:
- **Accuracy**.
- **Precision, Recall, y F1-Score**.
- **Matriz de ConfusiÃ³n**.
- **Curva ROC y AUC**.

Se comparan los resultados para identificar el mejor modelo basado en rendimiento.

---

## ğŸ“Š Resultados Obtenidos
Los resultados del anÃ¡lisis y los modelos entrenados mostraron lo siguiente:

1. **RegresiÃ³n LogÃ­stica**
   - Accuracy: **74.3%**
   - Buen equilibrio entre precisiÃ³n y recall.

2. **KNN**
   - Accuracy: **72.6%**
   - Menor rendimiento general, especialmente para la clase **mala calidad**.

3. **Random Forest Classifier**
   - Accuracy: **75.4%**
   - Mejor rendimiento general.
   - AUC: **0.82**.
   - **Random Forest** es seleccionado como el mejor modelo despuÃ©s de optimizaciÃ³n con GridSearchCV.

**Visualizaciones Generadas:**
- **ComparaciÃ³n de modelos** (barras de accuracy).
- **Matrices de ConfusiÃ³n**.
- **Curvas ROC-AUC**.

---

## ğŸ“ Estructura del Proyecto

mitic-data-science-gonza/ â”‚ â”œâ”€â”€ notebooks/ â”‚ â”œâ”€â”€ machine_learning/ â”‚ â”‚ â”œâ”€â”€ regresion/ â”‚ â”‚ â”‚ â”œâ”€â”€ clasificacion_basica.ipynb # Notebook principal â”‚ â”œâ”€â”€ data/ # Datos utilizados (opcional) â”œâ”€â”€ results/ # Resultados del modelo â”‚ â”œâ”€â”€ confusion_matrix.png # VisualizaciÃ³n de matriz de confusiÃ³n â”‚ â”œâ”€â”€ roc_curve.png # VisualizaciÃ³n de curva ROC â”‚ â”œâ”€â”€ comparison_accuracy.png â”‚ â””â”€â”€ README.md # DescripciÃ³n del proyecto


---

## ğŸš€ EjecuciÃ³n del Proyecto

### **Requisitos Previos**
- Python 3.8 o superior.
- LibrerÃ­as necesarias: `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`.

### **InstalaciÃ³n de Dependencias**
```bash
pip install -r requirements.txt

EjecuciÃ³n
Clona el repositorio:

bash
Copiar cÃ³digo
git clone https://github.com/gonzalofe/mitic-data-science-gonza.git
cd mitic-data-science-gonza
Abre el archivo notebook en Jupyter:

bash
Copiar cÃ³digo
jupyter notebook notebooks/machine_learning/regresion/clasificacion_basica.ipynb
Ejecuta cada celda secuencialmente para:

Cargar datos.
Preprocesar las caracterÃ­sticas.
Entrenar y evaluar los modelos.
Visualizar resultados.
